# Healthcare Provider Fraud Detection (Medicare Claims)

Endâ€‘toâ€‘end machineâ€‘learning pipeline to flag **potentially fraudulent healthcare providers** from Medicare claim patterns. The repository is **codeâ€‘first (Python)** and all **CSVs in this repo are programâ€‘generated outputs** (processed datasets and submissions) â€” not the original raw Kaggle files.

---

## ğŸš€ TL;DR
- **Goal:** Predict providerâ€‘level fraud (`PotentialFraud`) using claims and beneficiary data.
- **Approach:** Clean & merge â†’ feature engineering â†’ imbalance handling â†’ model training (LR, RF, IF) â†’ threshold tuning.
- **Repo layout:** Professional folder structure (`data/`, `models/`, `src/`, `README.md`).

---

## ğŸ“Š Dataset
- **Source:** Kaggle â€” [Healthcare Provider Fraud Detection Analysis](https://www.kaggle.com/datasets/rohitrox/healthcare-provider-fraud-detection-analysis/data)
- **Kaggle link (provided):** https://www.kaggle.com/datasets/rohitrox/healthcare-provider-fraud-detection-analysis/data
- **Tables:** Beneficiary, Inpatient, Outpatient, and Provider label table.
- **Target:** `PotentialFraud` (Yes/No) at provider level.

> ğŸ” **Note:** Raw Kaggle CSVs are **not** committed. The repository contains **processed CSVs** and **submission CSVs** that are **saved automatically by the program** during runs.

---

## ğŸ—‚ï¸ Repository Structure
```
â”œâ”€ data/                          # All program-generated CSVs
â”‚  â”œâ”€ processed/                  # Engineered datasets at provider level
â”‚  â””â”€ submissions/                # Final prediction CSVs
â”‚
â”œâ”€ models/                        # Saved models + transformers + metadata
â”‚  â”œâ”€ logistic_regression_threshold_60.joblib
â”‚  â”œâ”€ random_forest.joblib
â”‚  â”œâ”€ isolation_forest.joblib
â”‚  â”œâ”€ isolation_forest_pca_scaler.joblib
â”‚  â”œâ”€ isolation_forest_pca_transformer.joblib
â”‚  â”œâ”€ logistic_regression_scaler.joblib
â”‚  â”œâ”€ *metadata.json
â”‚  â””â”€ ...
â”‚
â”œâ”€ src/                           # Source code
â”‚  â””â”€ healthcare_fraud_detection.py
â”‚
â”œâ”€ README.md
â””â”€ requirements.txt (to be added)
```

> âœ… This structure is clean and professional: `data/` for outputs, `models/` for joblibs/jsons, `src/` for main Python code, and `README.md` at the top level.

---

## âš™ï¸ Setup
```bash
# 1) Create & activate a virtual environment
python -m venv .venv
.venv\Scripts\activate   # Windows
# source .venv/bin/activate   # Linux/Mac

# 2) Install dependencies
pip install -r requirements.txt
```
**Suggested requirements (edit if versions differ):**
```
pandas>=2.0
numpy>=1.24
scikit-learn>=1.3
imbalanced-learn>=0.11
matplotlib>=3.7
joblib>=1.3
```

---

## ğŸ§ª How to Run
### Run full pipeline
```bash
python src/healthcare_fraud_detection.py
```
This will:
- Load raw/processed data (depending on your setup)
- Engineer features
- Train models (LR, RF, IF)
- Apply thresholds (e.g., 0.60 for Logistic Regression)
- Save artifacts â†’ `models/`
- Save CSV outputs â†’ `data/processed/` and `data/submissions/`

### (Optional) Run with explicit args
```bash
python src/healthcare_fraud_detection.py \
  --raw_dir data/raw \
  --processed_dir data/processed \
  --models_dir models \
  --submissions_dir data/submissions \
  --model lr --threshold 0.60 --seed 42
```

---

## ğŸ“¦ Outputs (Programâ€‘Saved)
- **Models & Transformers** in `models/`
- **Processed CSVs** in `data/processed/`
- **Submissions** in `data/submissions/`

These are committed to repo for easy reproducibility.

---

## ğŸ—ï¸ Methodology
1. **Merge raw tables** â†’ provider level.
2. **Engineer features** â†’ claim counts, reimbursements, LOS, beneficiary diversity.
3. **Handle imbalance** â†’ class weights / resampling.
4. **Train models** â†’ Logistic Regression, Random Forest, Isolation Forest.
5. **Evaluate** â†’ Accuracy, Precision, Recall, F1, ROCâ€‘AUC.
6. **Persist** â†’ Models + scalers + metadata JSON + CSVs.

---

## ğŸ”® Inference Example
```python
import joblib, pandas as pd

X = pd.read_csv("data/processed/provider_features.csv")
clf = joblib.load("models/logistic_regression_threshold_60.joblib")
proba = clf.predict_proba(X)[:, 1]
X.assign(fraud_risk=proba).to_csv("data/submissions/predictions_lr.csv", index=False)
```

---

## ğŸ§­ Responsible Use
This project flags **potential** fraud for review. It does **not** prove actual fraud. Always validate with domain experts and policies.

---

## ğŸ™Œ Acknowledgments
- Kaggle dataset: *Healthcare Provider Fraud Detection Analysis*.
- Python ecosystem: pandas, scikitâ€‘learn, numpy, imbalancedâ€‘learn, matplotlib.

